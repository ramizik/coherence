"""Pydantic schemas for API request/response models.

These models match the TypeScript interfaces defined in frontend/types/index.ts.
Backend uses camelCase field names to match frontend directly (via alias).
"""
from enum import Enum
from typing import Optional, List
from pydantic import BaseModel, Field


# ========================
# Enums
# ========================

class ScoreTier(str, Enum):
    """Coherence score tier."""
    NEEDS_WORK = "Needs Work"
    GOOD_START = "Good Start"
    STRONG = "Strong"


class DissonanceType(str, Enum):
    """Type of visual-verbal dissonance."""
    EMOTIONAL_MISMATCH = "EMOTIONAL_MISMATCH"
    MISSING_GESTURE = "MISSING_GESTURE"
    PACING_MISMATCH = "PACING_MISMATCH"


class Severity(str, Enum):
    """Severity level of dissonance flag."""
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"


class ProcessingStatus(str, Enum):
    """Video processing status."""
    QUEUED = "queued"
    PROCESSING = "processing"
    COMPLETE = "complete"
    ERROR = "error"


# ========================
# Core Analysis Types
# ========================

class AnalysisMetrics(BaseModel):
    """Metrics extracted from video analysis."""
    eyeContact: int = Field(..., ge=0, le=100, description="Eye contact percentage (0-100)")
    fillerWords: int = Field(..., ge=0, description="Count of filler words")
    fidgeting: int = Field(..., ge=0, description="Count of fidgeting instances")
    speakingPace: int = Field(..., ge=0, description="Words per minute")
    speakingPaceTarget: Optional[str] = Field(None, description="Target WPM range, e.g., '140-160'")

    class Config:
        populate_by_name = True


class DissonanceFlag(BaseModel):
    """A single dissonance flag (visual-verbal mismatch)."""
    id: str = Field(..., description="Unique identifier")
    timestamp: float = Field(..., ge=0, description="Seconds from video start")
    endTimestamp: Optional[float] = Field(None, ge=0, description="End time for clip duration")
    type: DissonanceType = Field(..., description="Type of dissonance")
    severity: Severity = Field(..., description="Severity level")
    description: str = Field(..., description="What was detected")
    coaching: str = Field(..., description="Actionable fix advice")
    visualEvidence: Optional[str] = Field(None, description="What TwelveLabs detected")
    verbalEvidence: Optional[str] = Field(None, description="What Deepgram transcribed")

    class Config:
        populate_by_name = True


class TimelinePoint(BaseModel):
    """Point on the timeline heatmap."""
    timestamp: float = Field(..., ge=0, description="Seconds from video start")
    severity: Severity = Field(..., description="Severity for color coding")


class TranscriptSegment(BaseModel):
    """Optional transcript segment for detailed view."""
    text: str
    start: float
    end: float
    confidence: Optional[float] = None


# ========================
# Gemini Report Types
# ========================

class GeminiReport(BaseModel):
    """Natural language coaching report generated by Gemini.

    This provides a conversational, human-like coaching advice that's easy
    to read and understand. Written as if a presentation coach is giving
    direct feedback to the presenter.
    """
    # Main coaching advice - natural language, conversational tone
    coachingAdvice: str = Field(
        ...,
        description="Natural, conversational coaching advice written like a human coach giving feedback. "
        "Several sentences covering strengths, areas to improve, and actionable tips."
    )

    # Optional: Quick headline for the card
    headline: Optional[str] = Field(
        None,
        description="Short 5-10 word headline summarizing the overall assessment"
    )

    # Metadata
    generatedAt: Optional[str] = Field(None, description="ISO timestamp when report was generated")
    modelUsed: Optional[str] = Field(None, description="Gemini model version used")

    class Config:
        populate_by_name = True


class AnalysisResult(BaseModel):
    """Complete analysis result returned by backend.

    Endpoint: GET /api/videos/{videoId}/results
    """
    videoId: str
    videoUrl: str = Field(..., description="URL to serve video: /videos/{videoId}.mp4")
    durationSeconds: float
    coherenceScore: int = Field(..., ge=0, le=100, description="Coherence score 0-100")
    scoreTier: ScoreTier
    metrics: AnalysisMetrics
    dissonanceFlags: List[DissonanceFlag]
    timelineHeatmap: List[TimelinePoint]
    strengths: List[str] = Field(..., description="What presenter did well")
    priorities: List[str] = Field(..., description="Top 3 improvement areas")
    transcript: Optional[List[TranscriptSegment]] = None

    # Gemini comprehensive report (separate tab in frontend)
    geminiReport: Optional[GeminiReport] = Field(
        None,
        description="Comprehensive AI coaching report synthesized from all analysis sources"
    )

    class Config:
        populate_by_name = True


# ========================
# API Request/Response Types
# ========================

class UploadResponse(BaseModel):
    """Response from video upload.

    Endpoint: POST /api/videos/upload
    """
    videoId: str
    status: str = "processing"
    estimatedTime: int = Field(..., description="Seconds until complete")
    durationSeconds: float = Field(..., description="Video duration in seconds")

    class Config:
        populate_by_name = True


class StatusResponse(BaseModel):
    """Response from status check.

    Endpoint: GET /api/videos/{videoId}/status
    """
    videoId: str
    status: ProcessingStatus
    progress: int = Field(..., ge=0, le=100, description="Progress percentage 0-100")
    stage: str = Field(..., description="Current processing step for UX")
    etaSeconds: Optional[int] = Field(None, description="Estimated time remaining")
    error: Optional[str] = Field(None, description="Error message if status is error")

    class Config:
        populate_by_name = True


class ApiError(BaseModel):
    """Standard error response from backend."""
    error: str = Field(..., description="User-friendly message")
    code: str = Field(..., description="Error code (e.g., 'VIDEO_TOO_LARGE')")
    retryable: bool = Field(..., description="Show retry button if true")


# ========================
# Sample Video Types
# ========================

class SampleVideoResponse(BaseModel):
    """Response for loading a sample video."""
    videoId: str
    status: str = "complete"


class SampleVideoInfo(BaseModel):
    """Information about a pre-processed sample video with actual analysis data."""
    id: str = Field(..., description="Sample video ID (e.g., 'sample-1')")
    title: str = Field(..., description="Display title for the sample")
    score: int = Field(..., ge=0, le=100, description="Actual coherence score from analysis")
    scoreTier: ScoreTier = Field(..., description="Score tier (Needs Work, Good Start, Strong)")
    isCached: bool = Field(..., description="Whether this sample has cached results")
    flagCount: int = Field(0, ge=0, description="Number of coaching insights/flags")

    class Config:
        populate_by_name = True


class SampleVideosListResponse(BaseModel):
    """Response containing all available sample videos with their analysis data."""
    samples: List[SampleVideoInfo] = Field(..., description="List of sample videos")
    allCached: bool = Field(..., description="Whether all samples are cached and ready")
