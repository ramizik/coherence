# ğŸ¯ Coherence - AI Presentation Coach

**Win your next presentation with AI-powered body language feedback.**

Coherence is the first AI platform that detects **visual-verbal dissonance** â€” when your body language contradicts what you're saying. Built for students, professionals, and anyone who wants to present with confidence.

---

## ğŸš€ The Problem

- **75% of people** fear public speaking more than death
- **90% of presentation anxiety** stems from lack of objective feedback
- Existing tools (Yoodli, PowerPoint Coach) only analyze audio
- **55% of communication is non-verbal**, yet no tool catches body language mistakes

### What We Catch

âŒ **Emotional Mismatch** - Saying "I'm thrilled" with an anxious face
âŒ **Missing Gestures** - Saying "look at this chart" without pointing
âŒ **Pacing Issues** - Showing dense slides too briefly for comprehension

---

## ğŸ¥ Demo Video

> [Insert 2-minute demo video link here]

**Local Setup:** Run frontend and backend locally for development and testing

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Vite + React  â”‚  â† Frontend (TypeScript + TailwindCSS)
â”‚  Local Dev      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    FastAPI      â”‚  â† Backend (Python)
â”‚  Local Server   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼    â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Twelve â”‚ â”‚ Deepgram â”‚ â”‚ Gemini  â”‚
â”‚ Labs  â”‚ â”‚  (Audio) â”‚ â”‚ (Brain) â”‚
â”‚(Video)â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Frontend**
- Vite 6+ with React 18 - Build tool and UI framework
- TypeScript - Type safety
- TailwindCSS v4 - Glassmorphic UI
- shadcn/ui - Pre-built Radix UI components
- Lucide React - Icon system

**Backend**
- FastAPI - Python async web framework
- FFmpeg - Video frame extraction
- Pydantic - Data validation

**AI Services**
- **TwelveLabs** - Semantic video search (body language analysis)
- **Deepgram** - Real-time speech transcription
- **Gemini 1.5 Pro** - Multimodal synthesis & dissonance detection

---

## ğŸ¯ Key Features

### 1. Visual-Verbal Dissonance Detection
Our unique AI analyzes three dimensions simultaneously:
- **Speech Content** (what you say)
- **Body Language** (how you look)
- **Slide Pacing** (what you show)

### 2. Actionable Coaching
Not just metrics â€” we tell you exactly how to improve:
> "You said 'passionate' at 2:15 but your face showed anxiety. **Fix:** Smile with teeth and lean forward 10Â° when expressing enthusiasm."

### 3. Interactive Timeline
Color-coded heatmap showing exactly when dissonance occurs. Click any moment to jump to that timestamp.

### 4. Coherence Score (0-100)
Weighted algorithm combining:
- Eye contact percentage (30%)
- Filler word count (25%)
- Fidgeting frequency (20%)
- Speaking pace (15%)
- Dissonance penalties (10%)

---

## ğŸ“Š Sample Analysis

**Input:** 3-minute MBA pitch video

**Output:**
```json
{
  "coherenceScore": 67,
  "metrics": {
    "eyeContact": 85,
    "fillerWords": 8,
    "fidgeting": 6,
    "speakingPace": 142
  },
  "dissonanceFlags": [
    {
      "timestamp": 15.5,
      "type": "EMOTIONAL_MISMATCH",
      "severity": "HIGH",
      "description": "Said 'thrilled' with anxious expression",
      "coaching": "Smile with teeth, lean forward 10Â°"
    }
  ]
}
```

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Python 3.10+
- FFmpeg installed
- API keys for TwelveLabs, Deepgram, Gemini

### Frontend Setup
```bash
# From repository root
npm install
npm run dev
# Opens at http://localhost:3000
```

### Backend Setup
```bash
# From repository root
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Create .env file in repository root
# Add API keys: TWELVELABS_API_KEY=your_key_here

# Run backend server
uvicorn backend.app.main:app --reload --host 0.0.0.0 --port 8000
# Or use the provided script:
# Windows: .\run_backend.ps1
# Linux/Mac: ./run_backend.sh
# Runs at http://localhost:8000
```

### Environment Variables

**Frontend** (`frontend/lib/config.ts`)
- API base URL configured in `frontend/lib/config.ts` (defaults to `http://localhost:8000`)

**Backend** (`.env` in repository root)
```
TWELVELABS_API_KEY=your_key_here
DEEPGRAM_API_KEY=your_key_here
GEMINI_API_KEY=your_key_here
```

---

## ğŸ“ Project Structure

```
coherence/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ main.tsx            # React entry point
â”‚   â”œâ”€â”€ App.tsx             # Root component with routing
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ui/             # shadcn/ui components
â”‚   â”‚   â”œâ”€â”€ upload/         # Upload page components
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadPage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProcessingView.tsx
â”‚   â”‚   â”‚   â””â”€â”€ UploadZone.tsx
â”‚   â”‚   â”œâ”€â”€ results/        # Results dashboard components
â”‚   â”‚   â”‚   â”œâ”€â”€ ResultsPage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ VideoPlayer.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ CoachingCard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ScoreBadge.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ DissonanceTimeline.tsx
â”‚   â”‚   â”‚   â””â”€â”€ MetricsRow.tsx
â”‚   â”‚   â””â”€â”€ landing/        # Landing page components
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ config.ts       # API configuration
â”‚   â”‚   â”œâ”€â”€ mock-data.ts    # Mock data for development
â”‚   â”‚   â””â”€â”€ services/      # API service layer (if needed)
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ index.ts        # TypeScript interfaces
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py         # FastAPI entry point
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â””â”€â”€ videos.py   # Video API endpoints
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ video_service.py  # Video processing logic
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â””â”€â”€ schemas.py  # Pydantic schemas
â”‚   â”œâ”€â”€ twelvelabs/
â”‚   â”‚   â”œâ”€â”€ twelvelabs_client.py  # TwelveLabs client
â”‚   â”‚   â”œâ”€â”€ indexing.py          # Video indexing
â”‚   â”‚   â””â”€â”€ analysis.py          # Video analysis
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ videos/         # Uploaded video storage
â”œâ”€â”€ documentation/
â”‚   â”œâ”€â”€ ROADMAP.md          # Build plan and milestones
â”‚   â””â”€â”€ FIGMA_GUIDELINES.md # Frontend generation spec
â”œâ”€â”€ AGENTS.md               # AI assistant guidelines
â”œâ”€â”€ CLAUDE.md               # Backend development guidelines
â””â”€â”€ README.md
```

---

## ğŸª Demo Preparation

### Pre-Demo Checklist
- [ ] Index 3 sample videos in TwelveLabs
- [ ] Cache analysis results for instant loading
- [ ] Test offline mode (cached fallback)
- [ ] Verify all API keys are active
- [ ] Rehearse 3-minute pitch 4+ times
- [ ] Test local file upload works smoothly
- [ ] Backup laptop with identical local setup

### Demo Flow (3 minutes)
1. **[0:00-0:30]** Hook - Explain dissonance problem
2. **[0:30-1:30]** Show pre-analyzed sample with red flags
3. **[1:30-2:30]** Live demo - upload & analyze local video
4. **[2:30-3:00]** Close - Market size & CTA

---

## ğŸ§ª Testing

### Run Frontend Tests
```bash
cd frontend
npm test
```

### Run Backend Tests
```bash
cd backend
pytest tests/ -v
```

### Test Coverage Focus
- Upload â†’ Processing â†’ Results flow (critical path)
- API endpoint response shapes
- Dissonance detection logic
- Coherence score calculation

---

## ğŸ¯ Target Users

1. **College Students** (Primary)
   - Final presentations cause 95% anxiety
   - Need objective feedback before high-stakes demos
   - Budget-conscious ($9/month tier)

2. **MBA Students** (Secondary)
   - Pitch competitions with real money at stake
   - Want competitive edge in delivery
   - Willing to pay for premium features

3. **Corporate Sales** (Tertiary)
   - Training teams for client demos
   - B2B sales where delivery = deal closure
   - Enterprise contracts ($99/seat)

---

## ğŸ’° Business Model (Post-Hackathon)

### Freemium SaaS
- **Free Tier:** 1 video/month, basic metrics
- **Student ($9/mo):** 10 videos/month, full coaching
- **Professional ($29/mo):** Unlimited videos, slide analysis
- **Enterprise ($99/seat):** Team analytics, integrations

### Market Opportunity
- **TAM:** 50M students + professionals presenting annually
- **SAM:** 10M active presentation tool users
- **SOM:** 500K early adopters (Year 1 target)

---

## ğŸ“š Documentation

- [Frontend Guidelines](documentation/FIGMA_GUIDELINES.md) - Frontend generation and integration spec
- [Backend Guidelines](CLAUDE.md) - Backend development and API contracts
- [Agent Guidelines](AGENTS.md) - AI assistant guidelines and integration patterns
- [Roadmap](documentation/ROADMAP.md) - Build plan, milestones, and progress tracking

---

## ğŸ› Known Limitations (Hackathon Scope)

- âŒ No user authentication
- âŒ No video editing/trimming
- âŒ No database persistence (in-memory cache only)
- âŒ No mobile app (web-only, desktop-first design)
- âŒ No real-time streaming analysis
- âŒ Processing limited to 5-minute videos (demo target: 2-3 minutes)
- âš ï¸ Real analysis pipeline pending (currently returns mock data from backend)

---

## ğŸ“„ License

MIT License - Built for SB Hacks 2025

---

## ğŸ™ Acknowledgments

- **TwelveLabs** - Semantic video understanding API
- **Deepgram** - Real-time speech transcription
- **Google** - Gemini 1.5 Pro multimodal AI
- **Vite** - Frontend build tool
- **React** - UI framework
- **FastAPI** - Backend framework

---

**Built with â¤ï¸ in 24 hours | SBHacks 2025**