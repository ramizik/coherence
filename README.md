# ğŸ¯ Coherence - AI Presentation Coach

**Win your next presentation with AI-powered body language feedback.**

Coherence is the first AI platform that detects **visual-verbal dissonance** â€” when your body language contradicts what you're saying. Built for students, professionals, and anyone who wants to present with confidence.

---

## ğŸš€ The Problem

- **75% of people** fear public speaking more than death
- **90% of presentation anxiety** stems from lack of objective feedback
- Existing tools (Yoodli, PowerPoint Coach) only analyze audio
- **55% of communication is non-verbal**, yet no tool catches body language mistakes

### What We Catch

âŒ **Emotional Mismatch** - Saying "I'm thrilled" with an anxious face
âŒ **Missing Gestures** - Saying "look at this chart" without pointing
âŒ **Pacing Issues** - Showing dense slides too briefly for comprehension

---

## ğŸ¥ Demo Video

[![Coherence](https://img.youtube.com/vi/TbkoovSZkW0/0.jpg)](https://youtu.be/TbkoovSZkW0)

**Local Setup:** Run frontend and backend locally for development and testing

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Vite + React  â”‚  â† Frontend (TypeScript + TailwindCSS)
â”‚  localhost:3000 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    FastAPI      â”‚  â† Backend (Python, async)
â”‚  localhost:8000 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Parallel Processing
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼    â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Twelve â”‚ â”‚ Deepgram â”‚ â”‚ Gemini  â”‚
â”‚ Labs  â”‚ â”‚  (Audio) â”‚ â”‚ (Coach) â”‚
â”‚(Video)â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Frontend**
- Vite 6+ with React 18 - Build tool and UI framework
- TypeScript - Type safety
- TailwindCSS v4 - Glassmorphic dark theme UI
- shadcn/ui - Pre-built Radix UI components
- Lucide React - Icon system

**Backend**
- FastAPI - Python async web framework with CORS
- Async background tasks - Non-blocking video processing
- In-memory caching - Dict-based storage (no database)
- Pydantic - Request/response validation with camelCase output

**AI Services (All Integrated âœ…)**
- **TwelveLabs** - Video indexing + semantic analysis (Pegasus 1.2 model)
- **Deepgram** - Audio transcription with filler word detection
- **Gemini 1.5 Pro** - Natural language coaching report generation

---

## ğŸ¯ Key Features (All Implemented âœ…)

### 1. Visual-Verbal Dissonance Detection
Our AI pipeline analyzes video in parallel:
- **TwelveLabs**: Eye contact, fidgeting, gestures, facial expressions
- **Deepgram**: Speech transcription, filler words ("um", "uh", "like"), speaking pace
- **Gemini**: Synthesizes all data into natural coaching advice

### 2. Three Types of Dissonance Flags
| Type | Description | Example |
|------|-------------|---------|
| `EMOTIONAL_MISMATCH` | Positive words with anxious/flat expression | Saying "thrilled" while frowning |
| `MISSING_GESTURE` | Deictic phrases without pointing | "Look at this" without gesturing |
| `PACING_MISMATCH` | Speaking too fast/slow for content | Rushing through dense material |

### 3. Interactive Results Dashboard
- **Video Player** with custom controls and seek functionality
- **Dissonance Timeline** - Click severity markers to jump to timestamps
- **Coaching Cards** - Dismissible insights with "Jump to Moment" buttons
- **Transcript Panel** - Word-level transcript with filler word highlighting
- **Gemini Summary Card** - Natural language coaching advice

### 4. Coherence Score (0-100)
Weighted algorithm:
- Eye contact percentage: 30%
- Filler word count: 25% (fewer = better)
- Fidgeting frequency: 20% (fewer = better)
- Speaking pace: 15% (140-160 WPM optimal)
- Dissonance penalties: -10 per HIGH, -5 per MEDIUM severity flag

**Score Tiers:**
- 76-100: "Strong"
- 51-75: "Good Start"
- 0-50: "Needs Work"

---

## ğŸ“¡ API Endpoints (All Implemented âœ…)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `POST /api/videos/upload` | POST | Upload video (MP4/MOV/WebM, max 500MB) |
| `GET /api/videos/{id}/status` | GET | Poll processing status (0-100%) |
| `GET /api/videos/{id}/results` | GET | Fetch complete analysis results |
| `GET /api/videos/{id}/stream` | GET | Stream video file for playback |
| `GET /api/videos/samples/{id}` | GET | Load pre-cached sample video |
| `GET /health` | GET | Health check endpoint |

### Sample API Response

```json
{
  "videoId": "abc-123",
  "videoUrl": "/api/videos/abc-123/stream",
  "durationSeconds": 183.0,
  "coherenceScore": 67,
  "scoreTier": "Good Start",
  "metrics": {
    "eyeContact": 62,
    "fillerWords": 12,
    "fidgeting": 8,
    "speakingPace": 156,
    "speakingPaceTarget": "140-160"
  },
  "dissonanceFlags": [
    {
      "id": "flag-1",
      "timestamp": 45.2,
      "endTimestamp": 48.0,
      "type": "EMOTIONAL_MISMATCH",
      "severity": "HIGH",
      "description": "Said 'thrilled to present' but facial expression showed anxiety",
      "coaching": "Practice saying this line while smiling in a mirror.",
      "visualEvidence": "TwelveLabs: 'person looking anxious' at 0:43-0:48",
      "verbalEvidence": "Deepgram: 'thrilled' (positive sentiment)"
    }
  ],
  "transcript": [
    {"text": "Hello everyone, today I'm thrilled...", "start": 0.5, "end": 3.2}
  ],
  "geminiReport": {
    "headline": "Solid foundation to build on",
    "coachingAdvice": "Great job on your presentation! You did a wonderful job maintaining eye contact..."
  }
}
```

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Python 3.10+
- API keys for TwelveLabs, Deepgram, Gemini

### Frontend Setup
```bash
# From repository root
npm install
npm run dev
# Opens at http://localhost:3000
```

### Backend Setup
```bash
# From repository root
python -m venv venv
.\venv\Scripts\Activate.ps1   # Windows PowerShell
# or: source venv/bin/activate  # Linux/Mac

pip install -r requirements.txt

# Create .env file in repository root with:
# TWELVELABS_API_KEY=your_key
# DEEPGRAM_API_KEY=your_key
# GEMINI_API_KEY=your_key

# Run backend server
uvicorn backend.app.main:app --reload --host 0.0.0.0 --port 8000
```

### Environment Variables (`.env` in repository root)

```env
TWELVELABS_API_KEY=your_twelvelabs_key
DEEPGRAM_API_KEY=your_deepgram_key
GEMINI_API_KEY=your_gemini_key
```

---

## ğŸ“ Project Structure

```
coherence/
â”œâ”€â”€ index.html              # Vite entry point
â”œâ”€â”€ package.json            # Frontend dependencies
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ vite.config.ts          # Vite configuration
â”œâ”€â”€ tsconfig.json           # TypeScript configuration
â”‚
â”œâ”€â”€ frontend/               # React frontend
â”‚   â”œâ”€â”€ main.tsx            # Entry point
â”‚   â”œâ”€â”€ App.tsx             # Root component with navigation
â”‚   â”œâ”€â”€ index.css           # TailwindCSS styles
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ui/             # shadcn/ui components
â”‚   â”‚   â”œâ”€â”€ upload/
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadPage.tsx       # Main upload page
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadZone.tsx       # Drag-and-drop area
â”‚   â”‚   â”‚   â”œâ”€â”€ ProcessingView.tsx   # Status polling UI
â”‚   â”‚   â”‚   â””â”€â”€ SampleVideos.tsx     # Pre-cached samples
â”‚   â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”‚   â”œâ”€â”€ ResultsPage.tsx      # Main results dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ VideoPlayer.tsx      # Custom video player
â”‚   â”‚   â”‚   â”œâ”€â”€ ScoreBadge.tsx       # Circular score indicator
â”‚   â”‚   â”‚   â”œâ”€â”€ CompactMetrics.tsx   # Metrics bar
â”‚   â”‚   â”‚   â”œâ”€â”€ CoachingCard.tsx     # Dismissible coaching cards
â”‚   â”‚   â”‚   â”œâ”€â”€ DissonanceTimeline.tsx  # Interactive timeline
â”‚   â”‚   â”‚   â”œâ”€â”€ TranscriptPanel.tsx  # Word-level transcript
â”‚   â”‚   â”‚   â””â”€â”€ GeminiSummaryCard.tsx   # AI coaching summary
â”‚   â”‚   â””â”€â”€ landing/        # Landing page components
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api.ts          # API service layer
â”‚   â”‚   â””â”€â”€ mock-data.ts    # Mock data for fallback
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ api.ts          # TypeScript API types
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app + CORS
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â””â”€â”€ videos.py        # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ video_service.py    # Processing orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ deepgram_service.py # Deepgram wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ twelvelabs_service.py  # TwelveLabs wrapper
â”‚   â”‚   â”‚   â””â”€â”€ gemini_service.py   # Gemini wrapper
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â””â”€â”€ schemas.py       # Pydantic schemas
â”‚   â”œâ”€â”€ deepgram/
â”‚   â”‚   â”œâ”€â”€ deepgram_client.py   # SDK client
â”‚   â”‚   â””â”€â”€ transcription.py     # Audio transcription
â”‚   â”œâ”€â”€ twelvelabs/
â”‚   â”‚   â”œâ”€â”€ twelvelabs_client.py # SDK client
â”‚   â”‚   â”œâ”€â”€ indexing.py          # Video indexing
â”‚   â”‚   â””â”€â”€ analysis.py          # Semantic analysis
â”‚   â”œâ”€â”€ gemini/
â”‚   â”‚   â”œâ”€â”€ gemini_client.py     # SDK client
â”‚   â”‚   â””â”€â”€ synthesis.py         # Dissonance detection
â”‚   â”œâ”€â”€ cli.py                   # CLI testing tool
â”‚   â””â”€â”€ data/videos/             # Uploaded video storage
â”‚
â”œâ”€â”€ documentation/
â”‚   â”œâ”€â”€ ROADMAP.md          # Build plan
â”‚   â””â”€â”€ FIGMA_GUIDELINES.md # Frontend spec
â”œâ”€â”€ AGENTS.md               # AI assistant guidelines
â”œâ”€â”€ CLAUDE.md               # Backend guidelines
â””â”€â”€ README.md
```

---

## ğŸ”„ Processing Pipeline

```
Upload Video â”€â”¬â”€â–º Deepgram (5-10s)    â”€â”¬â”€â–º Merge Results â”€â–º Gemini Report â”€â–º Store
              â”‚   â””â”€â–º Transcript       â”‚   â””â”€â–º Score Calculation
              â”‚   â””â”€â–º Filler words     â”‚
              â”‚   â””â”€â–º Speaking pace    â”‚
              â”‚                        â”‚
              â””â”€â–º TwelveLabs (20-40s) â”€â”˜
                  â””â”€â–º Video indexing
                  â””â”€â–º Semantic analysis
                  â””â”€â–º Dissonance flags
```

**Processing Time:** ~45-60 seconds for 2-minute video

---

## ğŸ› Known Limitations

- âŒ No user authentication
- âŒ No database persistence (in-memory cache only)
- âŒ No mobile app (web-only, desktop-first design)
- âŒ Processing limited to 5-minute videos
- âŒ No video editing/trimming
- âœ… All AI services integrated (TwelveLabs, Deepgram, Gemini)

---

## ğŸ“š Documentation

- [Roadmap](documentation/ROADMAP.md) - Build plan, milestones, and progress
- [Frontend Guidelines](documentation/FIGMA_GUIDELINES.md) - Frontend generation spec
- [Backend Guidelines](CLAUDE.md) - Backend development and API contracts
- [Agent Guidelines](AGENTS.md) - AI assistant integration patterns
- [Backend README](backend/README.md) - Module documentation and CLI tool

---

## ğŸ™ Acknowledgments

- **TwelveLabs** - Semantic video understanding API
- **Deepgram** - Real-time speech transcription
- **Google** - Gemini 1.5 Pro multimodal AI
- **Vite** - Frontend build tool
- **React** - UI framework
- **FastAPI** - Backend framework

---

**Built with â¤ï¸ in 24 hours | SBHacks 2025**
